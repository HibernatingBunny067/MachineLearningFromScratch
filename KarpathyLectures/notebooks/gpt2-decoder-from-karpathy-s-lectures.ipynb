{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "----\n",
    "- this is a practise exercise to learn the workings of modern transformers used in LLMs\n",
    "- I followed the Karpathy's lectures on YouTube and made some changes as needed (for better efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-06T11:02:31.016300Z",
     "iopub.status.busy": "2026-01-06T11:02:31.015571Z",
     "iopub.status.idle": "2026-01-06T11:02:34.484322Z",
     "shell.execute_reply": "2026-01-06T11:02:34.483656Z",
     "shell.execute_reply.started": "2026-01-06T11:02:31.016268Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7defb99bc4d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T09:07:55.112361Z",
     "iopub.status.busy": "2026-01-06T09:07:55.111986Z",
     "iopub.status.idle": "2026-01-06T09:07:55.118531Z",
     "shell.execute_reply": "2026-01-06T09:07:55.117630Z",
     "shell.execute_reply.started": "2026-01-06T09:07:55.112321Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class config:\n",
    "    block_size = 8 ##context window\n",
    "    batch_size = 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:49:52.239451Z",
     "iopub.status.busy": "2026-01-02T12:49:52.239113Z",
     "iopub.status.idle": "2026-01-02T12:49:52.248119Z",
     "shell.execute_reply": "2026-01-02T12:49:52.247198Z",
     "shell.execute_reply.started": "2026-01-02T12:49:52.239423Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "==========\n",
      "Length of the dataset (all the characters):1115394\n"
     ]
    }
   ],
   "source": [
    "file_path = r'/kaggle/input/tiny-shakespeare-karpathys-repo/tiny_shakespeare.txt'\n",
    "with open(file_path,'r') as f:\n",
    "    text = f.read()\n",
    "print(text[:100])\n",
    "print('='*10)\n",
    "print(f'Length of the dataset (all the characters):{len(text)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a vocabulary from the text\n",
    "- here karpathy used the set() constructor, which is the most efficient approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:49:54.255967Z",
     "iopub.status.busy": "2026-01-02T12:49:54.255637Z",
     "iopub.status.idle": "2026-01-02T12:49:54.274788Z",
     "shell.execute_reply": "2026-01-02T12:49:54.273750Z",
     "shell.execute_reply.started": "2026-01-02T12:49:54.255940Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 65\n",
      "Vocabulary: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "characters = sorted(set(text)) ##takes out all the unique characters and sorts it, returning a list\n",
    "vocabulary_size = len(characters)\n",
    "\n",
    "print(f'Size of vocabulary: {vocabulary_size}')\n",
    "vocab = ''.join(characters)\n",
    "print('Vocabulary:',vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing the text\n",
    "- we are building a character level model, for which we'll first start with a lookup table for charcters -> index and inverse lookkup table for index -> characters\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:49:56.775729Z",
     "iopub.status.busy": "2026-01-02T12:49:56.775364Z",
     "iopub.status.idle": "2026-01-02T12:49:56.782868Z",
     "shell.execute_reply": "2026-01-02T12:49:56.782024Z",
     "shell.execute_reply.started": "2026-01-02T12:49:56.775700Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: My name is Harikesh \n",
      " Len of Input: 19\n",
      "Output(encoded): [25, 63, 1, 52, 39, 51, 43, 1, 47, 57, 1, 20, 39, 56, 47, 49, 43, 57, 46]\n",
      "Length of Encoded output: 19\n"
     ]
    }
   ],
   "source": [
    "ch2idx = {ch:idx for idx,ch in enumerate(characters)}\n",
    "idx2ch = {idx:ch for idx,ch in enumerate(characters)}\n",
    "\n",
    "def encode(text:str):\n",
    "    return [ch2idx[ch] for ch in text]\n",
    "\n",
    "def decode(ids:list):\n",
    "    return ''.join([idx2ch[idx] for idx in ids])\n",
    "\n",
    "example = 'My name is Harikesh'\n",
    "print(\n",
    "    f'Input: {example}',\n",
    "    '\\n',\n",
    "    f'Len of Input: {len(example)}'\n",
    "    '\\n'\n",
    "    f'Output(encoded): {encode(example)}'\n",
    "    '\\n'\n",
    "    f'Length of Encoded output: {len(encode(example))}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:49:58.778119Z",
     "iopub.status.busy": "2026-01-02T12:49:58.777274Z",
     "iopub.status.idle": "2026-01-02T12:49:58.935171Z",
     "shell.execute_reply": "2026-01-02T12:49:58.934034Z",
     "shell.execute_reply.started": "2026-01-02T12:49:58.778086Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394])\n"
     ]
    }
   ],
   "source": [
    "##creating the encoded representation of all the data in a tensor\n",
    "data = torch.tensor(encode(text),dtype=torch.long)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data in train and val\n",
    "- here we can't use a random split, because the text follows a semantic order which has to be preserved if we want our model to learn to generate text like Shakespeare\n",
    "- we'll use the first 90% data for training and rest 10% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:49:59.301795Z",
     "iopub.status.busy": "2026-01-02T12:49:59.301381Z",
     "iopub.status.idle": "2026-01-02T12:49:59.307614Z",
     "shell.execute_reply": "2026-01-02T12:49:59.306567Z",
     "shell.execute_reply.started": "2026-01-02T12:49:59.301757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Philosophy\n",
    "- any chunk of data with size 'd' that is sampled from the train data has 'd' number of training examples for the model\n",
    "- starting from the first character, we train the model to predict second then with the first two, the third and so on till the 'd-1'th element which is used to predict the d'th character\n",
    "- here the choice to take context size as 'd' is freely available to the user, with higher values of d requiring more compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:50:00.782580Z",
     "iopub.status.busy": "2026-01-02T12:50:00.782209Z",
     "iopub.status.idle": "2026-01-02T12:50:00.792428Z",
     "shell.execute_reply": "2026-01-02T12:50:00.791259Z",
     "shell.execute_reply.started": "2026-01-02T12:50:00.782547Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context: tensor([18]) -> 47\n",
      "for context: tensor([18, 47]) -> 56\n",
      "for context: tensor([18, 47, 56]) -> 57\n",
      "for context: tensor([18, 47, 56, 57]) -> 58\n",
      "for context: tensor([18, 47, 56, 57, 58]) -> 1\n",
      "for context: tensor([18, 47, 56, 57, 58,  1]) -> 15\n",
      "for context: tensor([18, 47, 56, 57, 58,  1, 15]) -> 47\n",
      "for context: tensor([18, 47, 56, 57, 58,  1, 15, 47]) -> 58\n"
     ]
    }
   ],
   "source": [
    "##example\n",
    "X = train_data[:config.block_size+1]\n",
    "y = train_data[1:config.block_size+1]\n",
    "\n",
    "for t in range(config.block_size):\n",
    "    context = X[:1+t]\n",
    "    label = y[t]\n",
    "    print(f'for context: {context} -> {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on generating the batch\n",
    "- karpathy's method randomly samples (batch_size,block_size) sample vectors from the input text\n",
    "- this stocasticity means that we may or may not use the whole dataset in training, while it maintains the IID assumptions and will be very beneficials for preventing overfitting there are other better ways to do it (in production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:50:02.776084Z",
     "iopub.status.busy": "2026-01-02T12:50:02.775739Z",
     "iopub.status.idle": "2026-01-02T12:50:02.803432Z",
     "shell.execute_reply": "2026-01-02T12:50:02.802452Z",
     "shell.execute_reply.started": "2026-01-02T12:50:02.776056Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_batch(data,context_window=config.block_size,batch_size=config.batch_size):\n",
    "    idx = torch.randint(len(data)-context_window,(batch_size,)) \n",
    "    X = torch.stack([data[i:i+context_window] for i in idx])\n",
    "    y = torch.stack([data[i+1:i+context_window+1] for i in idx])\n",
    "    return X,y\n",
    "\n",
    "xb,yb = get_batch(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiGram Language Model\n",
    "- this model effictively uses the statistical approach of calculating all the bigrams from the input text and arranging them in a table where rows and columns are the first and second character of the bigrams and the intersecting cell is the count of how many times the column character follows the row charater in the text\n",
    "- in PyTorch we can implement this using the nn.Embedding() layer which createst a table of (vocab_size,vocab_size) assigning random numbers in the cells and upon training we hope that the values in these cells approach the count (normalized over the rows) in the statistical table approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:50:03.702997Z",
     "iopub.status.busy": "2026-01-02T12:50:03.702667Z",
     "iopub.status.idle": "2026-01-02T12:50:03.710910Z",
     "shell.execute_reply": "2026-01-02T12:50:03.709784Z",
     "shell.execute_reply.started": "2026-01-02T12:50:03.702970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%writefile bigram.py\n",
    "class Bigram(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.lookup_table = nn.Embedding(vocab_size,vocab_size)\n",
    "    def forward(self,idx,labels=None):\n",
    "        logits = self.lookup_table(idx) #(B,T,C) -> (4,8,65)\n",
    "\n",
    "        if labels is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            labels = labels.view(B*T)\n",
    "            loss = F.cross_entropy(logits,labels)\n",
    "        return logits,loss\n",
    "        \n",
    "    def generate(self,idx,max_length):\n",
    "        ##idx is (B,T) for batch and timesteps of the input context\n",
    "        for _ in range(max_length-1):\n",
    "            logits,loss = self(idx[:,-1])\n",
    "            # logits = logits[:,:]\n",
    "            probs = F.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probs,num_samples=1)\n",
    "            idx = torch.cat([idx,idx_next],dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Untrained Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:50:05.613484Z",
     "iopub.status.busy": "2026-01-02T12:50:05.613090Z",
     "iopub.status.idle": "2026-01-02T12:50:05.712270Z",
     "shell.execute_reply": "2026-01-02T12:50:05.710935Z",
     "shell.execute_reply.started": "2026-01-02T12:50:05.613451Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "\n",
      "cfYCDRUZsYBsA?Y?vgB!ZWOEiAoezL:q&Avufr?gSGdWrp&Bxt-R?wo'TYhBChdIC-RDaRmEGENyouVg'UjyQNyQSpZUVeN:BZq\n"
     ]
    }
   ],
   "source": [
    "##testing untrained bigram model\n",
    "bigram_model = Bigram(vocab_size=vocabulary_size)\n",
    "logits,loss = bigram_model(xb,yb)\n",
    "\n",
    "input_context = torch.zeros((1,1),dtype=torch.long)\n",
    "outputs = bigram_model.generate(input_context,100).squeeze(0).tolist()\n",
    "print(len(outputs))\n",
    "print(decode(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the BiGram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T10:22:44.079633Z",
     "iopub.status.busy": "2025-12-31T10:22:44.079053Z",
     "iopub.status.idle": "2025-12-31T10:22:53.075447Z",
     "shell.execute_reply": "2025-12-31T10:22:53.074254Z",
     "shell.execute_reply.started": "2025-12-31T10:22:44.079599Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.708622932434082\n",
      "2.6894116401672363\n",
      "2.176974058151245\n",
      "2.289198160171509\n",
      "4.675192832946777\n",
      "2.432370662689209\n",
      "2.631892442703247\n",
      "2.386826753616333\n",
      "2.491130828857422\n",
      "2.5769729614257812\n",
      "\n",
      "G BENTCLOMNCI linn, onofeviapearb prstrde cooned insue'me wak hrs dotor LAno merareathabed hepe ar \n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(bigram_model.parameters(),lr=1e-3)\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "for steps in range(10000):\n",
    "    optimizer.step()\n",
    "    xb,yb = get_batch(train_data)\n",
    "\n",
    "    logits,loss = bigram_model(xb,yb)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps%1000 == 0:\n",
    "        print(loss.item())\n",
    "\n",
    "input_context = torch.zeros((1,1),dtype=torch.long)\n",
    "outputs = bigram_model.generate(input_context,100).squeeze(0).tolist()\n",
    "# print(len(outputs))\n",
    "print(decode(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Attention Mechanism -  the **matrix multiplication trick**\n",
    "- before writing any self-attention block we need to understand what attention does\n",
    "- here we used a toy example to understand what attention does in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:50:11.431588Z",
     "iopub.status.busy": "2026-01-02T12:50:11.430388Z",
     "iopub.status.idle": "2026-01-02T12:50:11.438204Z",
     "shell.execute_reply": "2026-01-02T12:50:11.437390Z",
     "shell.execute_reply.started": "2026-01-02T12:50:11.431534Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## a toy vector which represents the actual tensors in a language model \n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- currently the T tokens in each batch are not communicating with each other, in the BiGram model only the current token was taken to look forward in the lookup table based on the probability\n",
    "- but we need them to interact in a certain way, to establish this interaction we begin with the simplest form of interaction\n",
    "- **Averaging all the tokens in channels till 't' where t <= T for each batch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using the naive loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:50:13.636639Z",
     "iopub.status.busy": "2026-01-02T12:50:13.636286Z",
     "iopub.status.idle": "2026-01-02T12:50:13.659241Z",
     "shell.execute_reply": "2026-01-02T12:50:13.658158Z",
     "shell.execute_reply.started": "2026-01-02T12:50:13.636611Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.0652,  1.4098],\n",
       "         [ 1.6263,  0.0065],\n",
       "         [ 0.0182,  0.1661],\n",
       "         [ 0.8874,  0.1085],\n",
       "         [ 1.3757, -0.2378],\n",
       "         [ 0.6894, -0.2131],\n",
       "         [-0.2155,  1.4510],\n",
       "         [-0.3396, -1.6361]]),\n",
       " tensor([[1.0652, 1.4098],\n",
       "         [1.3458, 0.7081],\n",
       "         [0.9032, 0.5274],\n",
       "         [0.8993, 0.4227],\n",
       "         [0.9946, 0.2906],\n",
       "         [0.9437, 0.2066],\n",
       "         [0.7781, 0.3844],\n",
       "         [0.6384, 0.1318]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##code to do this operation also called BOW(bag of words)\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for batch_idx in range(B):\n",
    "    for time_step in range(T):\n",
    "        xprev = x[batch_idx,:time_step+1]\n",
    "        xbow[batch_idx,time_step] = torch.mean(xprev,0)\n",
    "\n",
    "x[0],xbow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using the matrix multiplication trick with **tril** or **triu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:50:15.991388Z",
     "iopub.status.busy": "2026-01-02T12:50:15.990886Z",
     "iopub.status.idle": "2026-01-02T12:50:16.014772Z",
     "shell.execute_reply": "2026-01-02T12:50:16.013863Z",
     "shell.execute_reply.started": "2026-01-02T12:50:15.991355Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "=====\n",
      "a:\n",
      "tensor([[8., 8.],\n",
      "        [5., 4.],\n",
      "        [9., 1.]])\n",
      "=====\n",
      "mask @ a:\n",
      "tensor([[8.0000, 8.0000],\n",
      "        [6.5000, 6.0000],\n",
      "        [7.3333, 4.3333]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.tril(torch.ones(3,3))\n",
    "mask = mask/torch.sum(mask,1,keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = mask@b\n",
    "\n",
    "print(f'mask=\\n{mask}')\n",
    "print('='*5)\n",
    "print(f'a:\\n{b}')\n",
    "print('='*5)\n",
    "print(f'mask @ a:\\n{c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using this trick to create a similar matrix \n",
    "- here the mask (T,T) when matirx multiplied to x (B,T,C) by the rules of brodcasting mask is brodcasted to (B,T,T)\n",
    "- and like the previous cell all the matrices in channels are averaged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:50:18.128697Z",
     "iopub.status.busy": "2026-01-02T12:50:18.128310Z",
     "iopub.status.idle": "2026-01-02T12:50:18.140960Z",
     "shell.execute_reply": "2026-01-02T12:50:18.140092Z",
     "shell.execute_reply.started": "2026-01-02T12:50:18.128667Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0652, 1.4098],\n",
       "         [1.3458, 0.7081],\n",
       "         [0.9032, 0.5274],\n",
       "         [0.8993, 0.4227],\n",
       "         [0.9946, 0.2906],\n",
       "         [0.9437, 0.2066],\n",
       "         [0.7781, 0.3844],\n",
       "         [0.6384, 0.1318]]),\n",
       " tensor([[1.0652, 1.4098],\n",
       "         [1.3458, 0.7081],\n",
       "         [0.9032, 0.5274],\n",
       "         [0.8993, 0.4227],\n",
       "         [0.9946, 0.2906],\n",
       "         [0.9437, 0.2066],\n",
       "         [0.7781, 0.3844],\n",
       "         [0.6384, 0.1318]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.tril(torch.ones(T,T))\n",
    "mask = mask/torch.sum(mask,1,keepdim=True)\n",
    "\n",
    "c = mask@x\n",
    "xbow[0],c[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using the softmax and mask filling approach to make learnable parameters\n",
    "- here we will make the 'wei' matrix change based on the data\n",
    "- implementing that change in next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:50:21.447570Z",
     "iopub.status.busy": "2026-01-02T12:50:21.446462Z",
     "iopub.status.idle": "2026-01-02T12:50:21.461718Z",
     "shell.execute_reply": "2026-01-02T12:50:21.460897Z",
     "shell.execute_reply.started": "2026-01-02T12:50:21.447520Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0,float('-inf'))\n",
    "\n",
    "wei = F.softmax(wei,dim=1)\n",
    "\n",
    "xbow3 = wei@x\n",
    "\n",
    "torch.allclose(xbow,xbow3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Defining how to create the wei matrix from data dependent parameters\n",
    "- the output is aggregated per head (16 here)\n",
    "- usually this is done for multiple head sizes which add upto C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T13:20:28.280456Z",
     "iopub.status.busy": "2026-01-02T13:20:28.280064Z",
     "iopub.status.idle": "2026-01-02T13:20:28.293885Z",
     "shell.execute_reply": "2026-01-02T13:20:28.291995Z",
     "shell.execute_reply.started": "2026-01-02T13:20:28.280421Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "head_size = 16\n",
    "key = nn.Linear(C,head_size,bias=False)\n",
    "query = nn.Linear(C,head_size,bias=False)\n",
    "value = nn.Linear(C,head_size,bias=False)\n",
    "\n",
    "##defining wei matrix \n",
    "\n",
    "k = key(x) ## (B,T,C)*(C,h) -> (B,T,C)*(B,C,h) => (B,T,h)\n",
    "q = query(x) ## (B,T,h)\n",
    "v = value(x) ## (B,T,h)\n",
    "\n",
    "wei = q@k.transpose(-2,-1) ## (B,T,h)*(B,T,h) -> (B,T,h)*(B,h,T) => (B,T,T)\n",
    "wei = wei.masked_fill(tril==0,float('-inf'))\n",
    "n_wei = wei\n",
    "wei = F.softmax(wei,dim=2)\n",
    "\n",
    "# xbow_self_attention = wei@x\n",
    "xbow_self_attention = wei@v ## (B,T,h)\n",
    "##instead of directly applying softmax to x we apply it to value(x)\n",
    "\n",
    "print(xbow_self_attention.shape)\n",
    "# print(torch.allclose(xbow_self_attention,xbow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T13:20:41.584759Z",
     "iopub.status.busy": "2026-01-02T13:20:41.584151Z",
     "iopub.status.idle": "2026-01-02T13:20:41.598790Z",
     "shell.execute_reply": "2026-01-02T13:20:41.597700Z",
     "shell.execute_reply.started": "2026-01-02T13:20:41.584717Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.1803,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "         [-1.5551, -2.1457,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "         [-0.0365, -0.1489,  0.0055,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "         [-0.8607, -1.2499, -0.0190, -0.6852,    -inf,    -inf,    -inf,    -inf],\n",
       "         [-1.2875, -1.6320, -0.0441, -0.9069, -1.3427,    -inf,    -inf,    -inf],\n",
       "         [-0.6344, -0.7472, -0.0255, -0.4186, -0.6070, -0.2945,    -inf,    -inf],\n",
       "         [ 0.0390, -0.8083,  0.0581, -0.3986, -0.7821, -0.4299,  0.6942,    -inf],\n",
       "         [ 0.5128,  1.6782, -0.0505,  0.8720,  1.5211,  0.8015, -0.8281,  0.3316]],\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6435, 0.3565, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3405, 0.3043, 0.3552, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1927, 0.1306, 0.4471, 0.2297, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1318, 0.0934, 0.4571, 0.1929, 0.1248, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1350, 0.1206, 0.2483, 0.1676, 0.1388, 0.1897, 0.0000, 0.0000],\n",
       "         [0.1644, 0.0704, 0.1675, 0.1061, 0.0723, 0.1028, 0.3165, 0.0000],\n",
       "         [0.0879, 0.2818, 0.0500, 0.1258, 0.2409, 0.1173, 0.0230, 0.0733]],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_wei[0],wei[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on attention\n",
    "- attention is just a connection mechanism which makes independent entities to communicate between them that is to say make them transfer their information among themselves\n",
    "- the particular attention mechanism discussed here is **self-attented decoder** where only the past nodes talk with each other and all the k,q and v matrices come from same tensor\n",
    "- there are multiple types of attentions, the one most adjacent to this type of attention is encoder architecture (used in BERT) where instead of mask filling we allow all the tokens to talk to each other at one time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Addressing the variance propogation in attention\n",
    "- the weight matrix formed from k and query multiplication carries a variance in the order of $h^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:58:53.814062Z",
     "iopub.status.busy": "2026-01-02T12:58:53.813710Z",
     "iopub.status.idle": "2026-01-02T12:58:53.823176Z",
     "shell.execute_reply": "2026-01-02T12:58:53.822178Z",
     "shell.execute_reply.started": "2026-01-02T12:58:53.814031Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3436, grad_fn=<VarBackward0>),\n",
       " tensor(2.9703, grad_fn=<VarBackward0>),\n",
       " tensor(0.1856, grad_fn=<VarBackward0>))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var(),n_wei.var(),(n_wei*(head_size)**-0.5).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Implementation and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities - Tokenizer, Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T11:47:23.994110Z",
     "iopub.status.busy": "2026-01-06T11:47:23.993504Z",
     "iopub.status.idle": "2026-01-06T11:47:24.006600Z",
     "shell.execute_reply": "2026-01-06T11:47:24.006015Z",
     "shell.execute_reply.started": "2026-01-06T11:47:23.994081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def get_batch(data,context_window=8,batch_size=8,DEVICE='cpu'):\n",
    "    idx = torch.randint(len(data)-context_window,(batch_size,)) \n",
    "    X = torch.stack([data[i:i+context_window] for i in idx])\n",
    "    y = torch.stack([data[i+1:i+context_window+1] for i in idx])\n",
    "    X = X.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "    return X,y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(model,train_data,val_data,eval_iters,context_windo,batch_size,device):\n",
    "    out = {}\n",
    "    splits = ['train','val']\n",
    "    model.eval()\n",
    "    for idx,data in enumerate([train_data,val_data]):\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X,y = get_batch(data=data,context_window=context_windo,batch_size=batch_size,DEVICE=device)\n",
    "            _,loss = model(X,y)\n",
    "            losses[k] = loss\n",
    "        out[splits[idx]] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class custom_tokenizer():\n",
    "    def __init__(self,data_path) -> None:\n",
    "        self.data_path = data_path\n",
    "        self.load()\n",
    "\n",
    "    def load(self):\n",
    "        try:\n",
    "            with open(self.data_path,'r') as f:\n",
    "                text = f.read()\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "\n",
    "        self.data = text\n",
    "        self.vocab = sorted(set(text))\n",
    "        self.ch2idx = {ch:idx for idx,ch in enumerate(self.vocab)}\n",
    "        self.idx2ch = {idx:ch for idx,ch in enumerate(self.vocab)}\n",
    "    \n",
    "    def encode(self,text:str):\n",
    "        return [self.ch2idx[ch] for ch in text] \n",
    "    \n",
    "    def decode(self,ids:list):\n",
    "        return ''.join([self.idx2ch[idx] for idx in ids])\n",
    "\n",
    "    def _size_(self):\n",
    "        return len(self.vocab)\n",
    "    \n",
    "    def get_coded_data_split(self):\n",
    "        data_tensor = torch.tensor(self.encode(self.data))\n",
    "        n = int(0.9*len(data_tensor))\n",
    "        train,val = data_tensor[:n],data_tensor[n:]\n",
    "        return train,val\n",
    "\n",
    "import math\n",
    "def get_lr(it,config):\n",
    "    # 1. Linear Warmup Phase\n",
    "    if it < config.warmup_iters:\n",
    "        return config.max_lr * (it + 1) / config.warmup_iters\n",
    "    \n",
    "    # 2. If we go past max_iters, just return min_lr\n",
    "    if it > config.max_iters:\n",
    "        return config.min_lr\n",
    "    \n",
    "    decay_ratio = (it - config.warmup_iters) / (config.max_iters - config.warmup_iters)\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # ranges 0..1\n",
    "    return config.min_lr + coeff * (config.max_lr - config.min_lr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T11:47:25.227549Z",
     "iopub.status.busy": "2026-01-06T11:47:25.226785Z",
     "iopub.status.idle": "2026-01-06T11:47:25.242781Z",
     "shell.execute_reply": "2026-01-06T11:47:25.242110Z",
     "shell.execute_reply.started": "2026-01-06T11:47:25.227522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(config.embed,4*config.embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*config.embed,config.embed),\n",
    "            nn.Dropout(config.dropout)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class causalAttention(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        assert config.embed % config.n_heads == 0\n",
    "        self.c_attn = nn.Linear(config.embed,3*config.embed,bias=False)\n",
    "        self.proj = nn.Linear(config.embed,config.embed,bias=False)\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_heads = config.n_heads\n",
    "        self.n_embed = config.embed\n",
    "    def forward(self,x):\n",
    "        B,T,C = x.shape\n",
    "\n",
    "        kqv = self.c_attn(x) ## x(B,T,C) -> kqv (B,T,3*C)\n",
    "\n",
    "        k,q,v = kqv.split(self.n_embed,dim=2) ## each matrix has dimension (B,T,C)\n",
    "\n",
    "        k = k.view(B,T,self.n_heads,C // self.n_heads).transpose(1,2) ## k(B,T,C) -> (B,T,n_heads,head_size) -> (B,n_heads,T,head_size)\n",
    "        q = q.view(B,T,self.n_heads,C // self.n_heads).transpose(1,2) ## q(B,T,C) -> (B,T,n_heads,head_size) -> (B,n_heads,T,head_size)\n",
    "        v = v.view(B,T,self.n_heads,C // self.n_heads).transpose(1,2) ## v(B,T,C) -> (B,T,n_heads,head_size) -> (B,n_heads,T,head_size)\n",
    "\n",
    "        ##attention calculation for each head we want (T,head_size) which we'll concatenate\n",
    "\n",
    "        wei = q @ k.transpose(-2,-1) * (k.shape[-1]**-0.5) ## wei: (B,n_heads,T,T)\n",
    "        trill = torch.tril(torch.ones(T,T,device=x.device)).view(1,1,T,T)\n",
    "        wei = wei.masked_fill(trill == 0,float('-inf'))\n",
    "\n",
    "        wei = F.softmax(wei,dim=-1)\n",
    "        wei = self.attn_dropout(wei)\n",
    "        \n",
    "        y = wei@v\n",
    "\n",
    "        y = y.transpose(1,2).contiguous().view(B,T,C)\n",
    "\n",
    "        out = self.proj(y)\n",
    "        out = self.resid_dropout(out)\n",
    "        return out\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.sa = causalAttention(config)\n",
    "        self.ffwd = FeedForward(config)\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(config.embed)\n",
    "        self.ln2 = nn.LayerNorm(config.embed)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class NanoGPT(nn.Module):\n",
    "    def __init__(self, config, vocab_size): # Added config\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, config.embed)\n",
    "        self.position_embedding_table = nn.Embedding(config.block_size, config.embed)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        # 3. THE BLOCKS: A stack of Transformer Blocks (Sequential is fine here)\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            Block(config) for _ in range(config.n_layer)\n",
    "        ])\n",
    "        \n",
    "        # 4. FINAL LAYER NORM: Standard Pre-Norm practice\n",
    "        self.ln_f = nn.LayerNorm(config.embed)\n",
    "        \n",
    "        # 5. LM HEAD: Projects from embedding dim back to vocab size\n",
    "        self.lm_head = nn.Linear(config.embed, vocab_size)\n",
    "\n",
    "        self.block_size = config.block_size\n",
    "\n",
    "    def forward(self, idx, labels=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        pos_idx = torch.arange(T, device=idx.device) \n",
    "        \n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, C)\n",
    "        pos_emb = self.position_embedding_table(pos_idx) # (T, C)\n",
    "        \n",
    "        x = tok_emb + pos_emb # (B, T, C)\n",
    "        x = self.dropout(x)\n",
    "        x = self.blocks(x) # (B, T, C)\n",
    "        \n",
    "        x = self.ln_f(x) # (B, T, C)\n",
    "        \n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "\n",
    "        if labels is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # Reshape for Cross Entropy (Standard PyTorch requirement)\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            labels = labels.view(-1)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_length):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_length):\n",
    "            # NEW: Crop context to the last block_size tokens\n",
    "            # If idx is longer than block_size, position embeddings will crash!\n",
    "            idx_cond = idx[:, -self.block_size:]\n",
    "            \n",
    "            # Get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            \n",
    "            # Focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            \n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            \n",
    "            # Append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T11:47:43.887308Z",
     "iopub.status.busy": "2026-01-06T11:47:43.887023Z",
     "iopub.status.idle": "2026-01-06T13:02:13.233952Z",
     "shell.execute_reply": "2026-01-06T13:02:13.233210Z",
     "shell.execute_reply.started": "2026-01-06T11:47:43.887283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656fb1f7b3214ab794622fc2357a8de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: train loss 4.2476, val loss 4.2447\n",
      "Step 300: train loss 2.3966, val loss 2.4189\n",
      "Step 600: train loss 1.9937, val loss 2.0757\n",
      "Step 900: train loss 1.7502, val loss 1.8946\n",
      "Step 1200: train loss 1.6093, val loss 1.7822\n",
      "Step 1500: train loss 1.5114, val loss 1.6998\n",
      "Step 1800: train loss 1.4448, val loss 1.6520\n",
      "Step 2100: train loss 1.3908, val loss 1.6010\n",
      "Step 2400: train loss 1.3554, val loss 1.5812\n",
      "Step 2700: train loss 1.3217, val loss 1.5587\n",
      "Step 3000: train loss 1.2899, val loss 1.5321\n",
      "Step 3300: train loss 1.2646, val loss 1.5340\n",
      "Step 3600: train loss 1.2446, val loss 1.5176\n",
      "Step 3900: train loss 1.2222, val loss 1.5104\n",
      "Step 4200: train loss 1.2065, val loss 1.5018\n",
      "Step 4500: train loss 1.1860, val loss 1.4953\n",
      "Step 4800: train loss 1.1716, val loss 1.4887\n",
      "Step 5100: train loss 1.1553, val loss 1.4817\n",
      "Step 5400: train loss 1.1417, val loss 1.4849\n",
      "Step 5700: train loss 1.1305, val loss 1.4871\n",
      "Step 6000: train loss 1.1171, val loss 1.4791\n",
      "Step 6300: train loss 1.1027, val loss 1.4761\n",
      "Step 6600: train loss 1.0935, val loss 1.4860\n",
      "Step 6900: train loss 1.0840, val loss 1.4798\n",
      "Step 7200: train loss 1.0737, val loss 1.4741\n",
      "Step 7500: train loss 1.0650, val loss 1.4789\n",
      "Step 7800: train loss 1.0587, val loss 1.4746\n",
      "Step 8100: train loss 1.0537, val loss 1.4822\n",
      "Step 8400: train loss 1.0469, val loss 1.4796\n",
      "Step 8700: train loss 1.0418, val loss 1.4845\n",
      "Step 9000: train loss 1.0356, val loss 1.4809\n",
      "EARLY STOPPING\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm, trange \n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class config:\n",
    "    n_layer = 6\n",
    "    block_size = 256\n",
    "    embed = 384\n",
    "    n_heads = 6\n",
    "    batch_size = 64\n",
    "    dropout = 0.2\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    max_iters_training = 10000\n",
    "    max_lr = 3e-4        \n",
    "    min_lr = 3e-5        \n",
    "    warmup_iters = 100   \n",
    "    max_iters = max_iters_training \n",
    "    eval_iters = 300\n",
    "    data_path = r'/kaggle/input/tiny-shakespeare-karpathys-repo/tiny_shakespeare.txt'\n",
    "\n",
    "# 1. Setup Data & Model\n",
    "tokenizer = custom_tokenizer(data_path=config.data_path)\n",
    "train_data, val_data = tokenizer.get_coded_data_split()\n",
    "\n",
    "model = NanoGPT(config, tokenizer._size_()) # Ensure this method returns int\n",
    "model.to(config.device)\n",
    "\n",
    "# 2. Setup Optimizer \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.max_lr)\n",
    "trLoss,valLoss = [],[]\n",
    "\n",
    "best_metric = float('inf') # Start at infinity so first loss is always \"better\"\n",
    "patience = 5               # How many evals to wait before stopping\n",
    "trigger = 0\n",
    "print('Starting Training....')\n",
    "\n",
    "# 3. Training Loop\n",
    "training_loop = trange(config.max_iters_training, desc='Training') \n",
    "\n",
    "for step in training_loop:\n",
    "    # A. Update Learning Rate\n",
    "    lr = get_lr(step,config)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    \n",
    "    # B. Evaluation (Every eval_iters)\n",
    "    if step % config.eval_iters == 0 or step == config.max_iters_training - 1:\n",
    "        losses = estimate_loss(model, train_data, val_data, config.eval_iters, config.block_size, config.batch_size, config.device)\n",
    "        training_loop.set_postfix(train_loss=losses['train'].item(), val_loss=losses['val'].item(), lr=lr)\n",
    "        tqdm.write(f\"Step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        trLoss.append(losses['train'].item())\n",
    "        valLoss.append(losses['val'].item())\n",
    "        if(losses['val'] < best_metric):\n",
    "            best_metric = losses['val']\n",
    "            trigger = 0\n",
    "            torch.save(model.state_dict(),'nanoGPT.pth')\n",
    "        else:\n",
    "            trigger+=1\n",
    "\n",
    "    if trigger > patience:\n",
    "        print('EARLY STOPPING')\n",
    "        break\n",
    "\n",
    "    # C. Training Step\n",
    "    xb, yb = get_batch(train_data, config.block_size, config.batch_size, config.device)\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True) \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# print(\"Trained model output:\\n\")\n",
    "# context = torch.zeros((1, 1), dtype=torch.long, device=config.device)\n",
    "# print(tokenizer.decode(model.generate(context, 500).squeeze(0).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:02:39.452697Z",
     "iopub.status.busy": "2026-01-06T13:02:39.452026Z",
     "iopub.status.idle": "2026-01-06T13:02:39.641552Z",
     "shell.execute_reply": "2026-01-06T13:02:39.640910Z",
     "shell.execute_reply.started": "2026-01-06T13:02:39.452670Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Evaluation Step')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(1,2,figsize=(8,4),sharex = True)\n",
    "ax[0].plot(trLoss)\n",
    "ax[0].grid()\n",
    "ax[0].set_ylabel('Training-Loss')\n",
    "ax[0].set_xlabel('Evaluation Step')\n",
    "ax[1].plot(valLoss)\n",
    "ax[1].grid()\n",
    "ax[1].set_ylabel('Validaiton-Loss')\n",
    "ax[1].set_xlabel('Evaluation Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:09:55.331583Z",
     "iopub.status.busy": "2026-01-06T13:09:55.331013Z",
     "iopub.status.idle": "2026-01-06T13:10:46.587834Z",
     "shell.execute_reply": "2026-01-06T13:10:46.587238Z",
     "shell.execute_reply.started": "2026-01-06T13:09:55.331558Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model output:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = NanoGPT(config,tokenizer._size_())\n",
    "model.load_state_dict(torch.load(r'/kaggle/working/nanoGPT.pth',map_location=config.device))\n",
    "model.to(config.device)\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=config.device)\n",
    "model_output = tokenizer.decode(model.generate(context, 10000).squeeze(0).cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:11:11.203084Z",
     "iopub.status.busy": "2026-01-06T13:11:11.202409Z",
     "iopub.status.idle": "2026-01-06T13:11:11.206506Z",
     "shell.execute_reply": "2026-01-06T13:11:11.205908Z",
     "shell.execute_reply.started": "2026-01-06T13:11:11.203056Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Do not because the life on the rebels,\n",
      "I have deserved with no quite and dargems.\n",
      "If it be daughter, I sever'd well-been secret\n",
      "And therefolds sight 't:' be the preciound\n",
      "That to the Edward blindness, and masks him;\n",
      "The same our aid, and let perille,\n",
      "I pleade you banished him: if my loyal,\n",
      "Doing out an in hour uprincets of pirect\n",
      "To famish'd opposite thy fall,\n",
      "We are colours in our daughter's womb in:\n",
      "'antily, not raged me too, so much show'd her\n",
      "Undon your counterse must to a father's.\n",
      "\n",
      "BRUTUS:\n",
      "O lamentation!\n",
      "Ere farewell: for well.\n",
      "\n",
      "SICINIUS:\n",
      "He come upon, hither\n",
      "Most abotial.\n",
      "\n",
      "CORIOLANUS:\n",
      "Come, that's it face:\n",
      "What batters it is come to Braught with Laurenca?\n",
      "Why, what? then, Warwick, and thy war\n",
      "That makes rapkind by the people\n",
      "In thee service and cennice myself. Was now\n",
      "none, fulless, stood issieges, that followers;\n",
      "these was bed induke, who still, thou knows\n",
      "is, anon his child: why, I cannight;\n",
      "Yet therefore have he beet worthip the\n",
      "sings begue after?\n",
      "\n",
      "AUTOLYCUS:\n",
      "This fly, they\n",
      "'Tis a man, I pray yours; and welcome.\n",
      "\n",
      "Clown:\n",
      "Sir, farewell, sir.\n",
      "\n",
      "First Senator:\n",
      "Clarence, amaudiers:\n",
      "His letters at he is himself and forsworn; so he\n",
      "see his with upon buttery footing thunded\n",
      "the crown rest numbering and husbands. Ned,\n",
      "Her dresses, sir, away wither: the ferruon'd, as I didslive not\n",
      "knowledges over thy heafe, wonder you, you\n",
      "not upon my aum: good neither says Withwalt\n",
      "crims our sift and with neced love; 'tis he\n",
      "truly fear'--a briddle-plot sold all baggage!--what fan?\n",
      "We art thou desired by the maidens?\n",
      "But wilt then mine hath call'd him him?\n",
      "\n",
      "BERK:\n",
      "Place, ho! thou hast post to break! Why, thou canst tend\n",
      "My life did breathing: and thy faither properhet,\n",
      "Play the gimm's shame I about my labele. O, his tear;\n",
      "My school-bented Insciance, I looke\n",
      "That is surrupting likefuly phrish,\n",
      "To these wronges of such roundly neck,\n",
      "By many other cry harmled barench;\n",
      "That $ick shame to that hear of a streets,\n",
      "And lead upon to the diff, and honour daughter,\n",
      "And liberty in the measure weeping the\n",
      "Duke inveytness their thou dead'sts to;\n",
      "And I am not our forceiver friends,\n",
      "Ared before the boar of it in unscustant.\n",
      "To dishonour, and this it by tit;\n",
      "He complain but an admitation.\n",
      "Ones, you, faire, welcome but the stream,\n",
      "That cannot dig but yet; which haste nature\n",
      "Is am in patient in certain'd in a tflemate dows.\n",
      "Is it wild not, and spict these lights? Let's writed\n",
      "The rottening stem, you\n",
      "Speake me wot; but yon other absolument\n",
      "With pass body possessiciet, you'll make\n",
      "And take off your your contract forced me:\n",
      "You would you know the dead I, the mighty will;\n",
      "And that in red, rules me in the will of his\n",
      "Irist the words that those choices of you mortal's wail,\n",
      "The house if any bold's poor leniant;\n",
      "I speak you mine eyes my stronger's brow'd oath;\n",
      "England with our structeth o'er death,\n",
      "My tenderning overthrow; and, that full young defence,\n",
      "While I my truth thrive hate, though in Kathary.\n",
      "You ray from hear, what men the main we see\n",
      "First to the seeking is mourner: this duke\n",
      "He hath his place waved water to\n",
      "Plack up him. I neglife, are hencedary.\n",
      "\n",
      "ANGELO:\n",
      "I'll so: very till there you on the make,\n",
      "If you be determined with fond langung\n",
      "Ere misering'd.\n",
      "\n",
      "LADY ANNE:\n",
      "Go, better, my lord, hope, I cheer than that we stay\n",
      "The cool-trembling.\n",
      "\n",
      "ANTIGON:\n",
      "It shall slaighter Camillo, I beg each,\n",
      "To please the white I high wanton in\n",
      "After such birth their theads.\n",
      "And I bear me old your haste.\n",
      "\n",
      "Third Watchman:\n",
      "What!\n",
      "Is provost! What say a counterfeit?\n",
      "Shall I would be much ere, I love this sure?\n",
      "Had I not way, Paulina, be hanged to He\n",
      "hath spended shap his butched at the feast\n",
      "and parted for aws: cry against with reach\n",
      "Upon his hand; and, as it aptle, I thine\n",
      "take in a feasting and tresperity, she, like an eno,\n",
      "that givety bere musicians here. You have\n",
      "done your readies butter wonds: shall I have tends\n",
      "up the kingly.\n",
      "\n",
      "CORIOLANUS:\n",
      "A general numble with heavier comfort\n",
      "A man wan the proclaim of yourself. Tulas, man?\n",
      "\n",
      "First Mumianon:\n",
      "Now, let's true, you say 'tis there:' A lie it!\n",
      "And so play the tables,--for her eye, no smile--\n",
      "\n",
      "CORIOLANUS:\n",
      "Lord Saint S!\n",
      "Why, sir George-my remorses!\n",
      "Full of death order thy name bury!\n",
      "\n",
      "PETER:\n",
      "Yes, looks on thy hand. Bagot, thou art,\n",
      "A miscare that I have, be it eardly yer,\n",
      "And I, my father's hell,\n",
      "That it hand's to known.\n",
      "\n",
      "PAULINA:\n",
      "My lord: I know me,\n",
      "Have well meet at the third place.\n",
      "\n",
      "Nurse:\n",
      "We shall we all have found him hanged where't\n",
      "For direct Northumberland? we know it labour,\n",
      "Stay the queen's wife. Marcius\n",
      "Or winch we for of give me?\n",
      "\n",
      "Messenger:\n",
      "A love in our like alion to couraging.\n",
      "\n",
      "JOHN OF GAUNT:\n",
      "Madam! we have the shown wrongled it in he\n",
      "fellow to conceal'd in Rome. Come, come succeeding:\n",
      "And I am for my kingly whip, my lord; I\n",
      "have none.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "But our issues, my lord.\n",
      "\n",
      "POMPEY:\n",
      "My proclainted means:\n",
      "These lords subders! men that it may,\n",
      "And are they thus; for which our chaped\n",
      "To supper Cliffordhall; I was danced to mine, go love\n",
      "Unless my trust and Oxford my view to wail.\n",
      "\n",
      "HENRY PERCY:\n",
      "Most neck? it is a great.\n",
      "Was a many-footh: be time to-morrow,\n",
      "That is my life's with morn swort with thy fain arms,\n",
      "That empty on of when thy tumbers! they are for\n",
      "their winddenct on suffice as a misfied hond\n",
      "Either of gains! Nowine would goes to guest: sgain\n",
      "will but walk my offence imprecting hangs; sharewith\n",
      "yet be gone for us. I wake the wife off with God trast\n",
      "the I cough at itself and great tarry her:\n",
      "she comes the matter from your life.\n",
      "\n",
      "SLY:\n",
      "He is, you might needs have kill husbandness\n",
      "wash'd; he cares my enough fetchesy: but back\n",
      "yet ago, friar and forward\n",
      "All never come all his plucker\n",
      "Where every reasons will the duke\n",
      "Had says me in thy loss to beatt murder. What can\n",
      "not telling what I do rise mercy, by\n",
      "those sight son: which we have espassaddely well\n",
      "oft to his force to Bolingbroke's pass.\n",
      "\n",
      "SICINIUS:\n",
      "God from proud we knight your sons; that is't\n",
      "ink, to putuase you to conference you him that\n",
      "you in; anour you a pause o' the prince.\n",
      "\n",
      "Bourth Camillo:\n",
      "Go you tell you now; then, lessing and hangment\n",
      "me in your Paulina. This your great self withal were you\n",
      "kisse-complagued to his very more?\n",
      "\n",
      "LADY CAPULET:\n",
      "My lord, art thou sit thy cur after.\n",
      "\n",
      "HASTINGS:\n",
      "Against thou unpleasant: I, incensed muccupin\n",
      "Will po one to hence or your highShy lord?\n",
      "\n",
      "Nurse:\n",
      "I, have seen him in himself. Have amas you.\n",
      "\n",
      "CLAUDINA:\n",
      "The army man, boy?\n",
      "That call used him by my that trences,\n",
      "That then so lice to down friend. For this plaw should I\n",
      "Come not miscalling\n",
      "Till these advatients. The noble graves at good\n",
      "Infectory from his falcon in't ham: but it\n",
      "Is present of her sort a bloody windowed.\n",
      "What is my soldier?\n",
      "\n",
      "QUEEN MARGARET:\n",
      "Neck, and thus kill, I protest these three his\n",
      "own fortuness, heirter's partings and place, the breast, threef,\n",
      "The merrime, dissester blot; for not frow, for fair like\n",
      "That treached tride privilenes, denies on an iighty tongue!\n",
      "The every craft kneed shook of devoted Creat\n",
      "is our blume. I am all alladys Aumerle, and\n",
      "the neckets clear the weighted traitor brother-brace. Than with\n",
      "dying trouble a woman broas; and thy govern, 'tis luck\n",
      "thereafters, like sixaled for eye,\n",
      "betimed for more entering have in hers,\n",
      "and to assump to the year something, keep\n",
      "The lawy her pity thou liest dambles,\n",
      "Which to pincely findlous, my country's ill,\n",
      "Or else then it better with a most teat: who\n",
      "Thou harst heard thief. O, get him above:\n",
      "I have dined march.\n",
      "\n",
      "SICINIUS:\n",
      "Why, sir,\n",
      "You half a wudgewise.\n",
      "\n",
      "Can if thou been a-viside voice: 'tis young\n",
      "and he crowned with holder, and your metifle proceeding and\n",
      "request-sweet lay-wife\n",
      "with Cominius, one removes, heir\n",
      "arribbed in such afford; if it they spent carrise.\n",
      "But it may soother. Now\n",
      "a follow noi!\n",
      "\n",
      "MENENIUS:\n",
      "Not a thousand man see, I cry you.\n",
      "\n",
      "MENENIUS:\n",
      "I lay as the man new upon myself this part.\n",
      "O, that hand our apelot in Clifford he meet, I\n",
      "hope here; shall there's all art for your baggain, and\n",
      "mend not the Partian commition\n",
      "And her compened--in the book word of love prisons,\n",
      "out of the deputy turning; and every bones\n",
      "knowledge of the tale perforcement hangs out,\n",
      "For wave with yoke the old man! Dales aloof!\n",
      "litter thousand much now\n",
      "To mockers crastal, curel of noble ctain he\n",
      "samed to-day, he is into cawara, of what had richmity\n",
      "sons at his evil-tombling youth, and are hand,\n",
      "never then which he do't, the dolex with so\n",
      "sweeter become hither. Good Catesar your hate;\n",
      "good ever over chastive a place, a\n",
      "parcel again, friend Play's too, and more, shall.\n",
      "Now how come the friar of this?\n",
      "\n",
      "First Servingman:\n",
      "Is all a nady to passe\n",
      "How the ten hath been you, hath not so do holy rack\n",
      "Her reprous on him.\n",
      "\n",
      "Second Servingman:\n",
      "It is, best enough with the healing such a\n",
      "peace: the pair hath done s muckole a curson; thine, this sun,\n",
      "it will not stay to put for you, stonew\n",
      "your soldiers.\n",
      "\n",
      "Third Citizen:\n",
      "I know God, hath me happy interceiting most blind:\n",
      "Here calls he suspicious Marcius.\n",
      "\n",
      "TYBALET:\n",
      "Give me first: no more.\n",
      "\n",
      "CORIOLANUS:\n",
      "My lord, and daughter be fift.\n",
      "\n",
      "CLARENCE:\n",
      "Choosed for hither, the air needlest lament\n",
      "Being a world first a plain, I find them prepart;\n",
      "How doth better them wase dither carm\n",
      "The state and blemish'd helments:\n",
      "The law upon the fair and this impediment\n",
      "That thanknesday's the storm and in the sweat\n",
      "Will inform my brave. Thus we are metiting away?\n",
      "Mercy best in him noble thus succond me:\n",
      "It lives to think a bed-for fallow; our eye\n",
      "Mistress; and husbands as yet our comfort and\n",
      "Whereto go, the ease mend, and like night requite\n",
      "Was thee eagle lift of his about\n",
      "With liberady: was we title could from him,\n",
      "And make might respect him murderous of the eary;\n",
      "If yond how now your saying, since he his king's,\n",
      "With his cheeks loves and lunes of this enemy.\n",
      "Peters, what last? for you woman.\n",
      "Is't string what seen, good sitten bastard,\n",
      "It likely him a'en him upon all.\n",
      "\n",
      "BENVOLIO:\n",
      "Titus a free of latic in capals and bellieve\n",
      "The princit sinEly,\n",
      "Could moe and thy love of followers I had got,\n",
      "To her fresherous and humble;\n",
      "The younger's place is a power of mother.\n",
      "Unctop, thy swift and law-aged hate thy sw\n"
     ]
    }
   ],
   "source": [
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T13:11:02.934451Z",
     "iopub.status.busy": "2026-01-06T13:11:02.933715Z",
     "iopub.status.idle": "2026-01-06T13:11:02.938588Z",
     "shell.execute_reply": "2026-01-06T13:11:02.937643Z",
     "shell.execute_reply.started": "2026-01-06T13:11:02.934419Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_file = r'/kaggle/working/demo.txt'\n",
    "\n",
    "with open(output_file,'w') as f:\n",
    "    f.write(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9158157,
     "sourceId": 14343225,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
