# Implemented Vision Transformer (from 2016 paper) from scratch 

## What is a Vision Transformer ?
- Like a language model, vision transformers use attention and tokenized images to understand it's content
- Image patches are treated as tokens, with Positional embeddings serving as the proxy for the spatial orientation of that patch
- 